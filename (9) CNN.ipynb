{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "y5Woj3fCOG87",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Convolution Neural Network"
      ]
    },
    {
      "metadata": {
        "id": "dsvb6PXzd0VX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rg8uALZRd2nI",
        "colab_type": "code",
        "outputId": "9ee1d820-9be0-4932-ce83-c5467840e5a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "cell_type": "code",
      "source": [
        "mnist=input_data.read_data_sets('mnist',one_hot=True)\n",
        "mnist"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-4-6bd1be727d09>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting mnist/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting mnist/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting mnist/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting mnist/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7fc4378ec710>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7fc4378ec550>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7fc3f2c90cc0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "iTUCbQCHpV9D",
        "colab_type": "code",
        "outputId": "f8a4cd60-87df-4da8-ac00-138c782d2eb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(mnist.train.images.shape)\n",
        "print(mnist.train.labels.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(55000, 784)\n",
            "(55000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "my2e2ZO2pqXA",
        "colab_type": "code",
        "outputId": "4ae8481a-37aa-4148-9abb-2e831a181950",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(mnist.test.images.shape)\n",
        "print(mnist.test.labels.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 784)\n",
            "(10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1Kq3FpQXqSaX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "new=mnist.train.images[1]\n",
        "new_1=np.resize(new,(28,28))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7bdT8-r-qeTd",
        "colab_type": "code",
        "outputId": "d61c5a40-00c1-4d86-8fd4-5d91492907e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(new_1,cmap='Dark2')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fc3effb44a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrtLvAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fc3f2c77278>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "ahHspN7WrVYS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YMV_4GWV5Whh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Variables to be used later in our implementation.\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "WEYfkDTz6btg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Building the model"
      ]
    },
    {
      "metadata": {
        "id": "Sc5P-PS16H4D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "learning_rate = 0.01\n",
        "training_epochs = 50 # training epoch\n",
        "batch_size = 128\n",
        "display_step = 10\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ID3Vcc09-S36",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Network Parameters\n",
        "n_input = 784  # MNIST data input (img shape: 28*28)\n",
        "n_classes = 10  # MNIST total classes (0-9 digits)\n",
        "dropout = 0.75  # Dropout, probability to keep units\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DfFNiA1QlP1d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dZScRGBw-jxk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### tf graph input"
      ]
    },
    {
      "metadata": {
        "id": "nhPEWYNv-W_Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x=tf.placeholder(tf.float32,[None,n_input])\n",
        "y=tf.placeholder(tf.float32,[None,n_classes])\n",
        "\n",
        "keep_prob = tf.placeholder(tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6V_B4vUI-5SR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Creating the Convolution.\n",
        "def conv2d(x,w,b,stride=1):\n",
        "  \n",
        "  \n",
        "  x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
        "  x = tf.nn.bias_add(x, b)\n",
        "  return tf.nn.relu(x)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h-l0nc1X_X-Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Creating the MaxPool.\n",
        "#Maxpool layer.\n",
        "def maxpool2d(x,k=2):\n",
        "    return tf.nn.max_pool(x,ksize=[1,k,k,1],stride=[1,k,k,1],padding='SAME')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8OjpMB1834a_",
        "colab_type": "code",
        "outputId": "c73c1e3e-5721-4915-d7d2-97e8bf978445",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1751
        }
      },
      "cell_type": "code",
      "source": [
        "def model(x,weight,biase,dropout):\n",
        "    \n",
        "    # Reshape input picture\n",
        "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
        "    #Layer 1\n",
        "    conv1=tf.nn.conv2d(x,weight['w1'],strides=[1,1,1,1],padding='SAME')\n",
        "    hidden1=tf.nn.relu(conv1+biase['b1'])\n",
        "    # Max Pooling (down-sampling)\n",
        "    pool1=tf.nn.max_pool(hidden1,[1,2,2,1],[1,2,2,1],padding='SAME')\n",
        "    #Layer 2\n",
        "    conv2=tf.nn.conv2d(pool1,weight['w2'],strides=[1,1,1,1],padding='SAME')\n",
        "    hidden2=tf.nn.relu(conv2+biase['b2'])\n",
        "    # Max Pooling (down-sampling)\n",
        "    pool2=tf.nn.max_pool(hidden2,[1,2,2,1],[1,2,2,1],padding='SAME')\n",
        "    \n",
        "     # Flattern the convolution output\n",
        "        \n",
        "#    shape = pool2.get_shape().as_list()\n",
        "#    reshape=tf.reshape(pool2,[shape[0],shape[1]*shape[2]*shape[3]])\n",
        "\n",
        "    # Fully connected layer\n",
        "    # Reshape conv2 output to fit fully connected layer input\n",
        "    fc1=tf.reshape(pool2,[-1,weight['wc1'].get_shape().as_list()[0]])\n",
        "    fc1=tf.add(tf.matmul(fc1,weight['wc1']),biase['bc1'])\n",
        "    fc1=tf.nn.relu(fc1)\n",
        "    # add dropout\n",
        "    fc1 = tf.nn.dropout(fc1, keep_prob)\n",
        "    #output.\n",
        "    \n",
        "    output=tf.add(tf.matmul(fc1,weight['w_out']),biase['b_out'])\n",
        "    return output\n",
        "#create the layer of weight and biases.\n",
        "  \n",
        "    \n",
        "   # 5x5 conv, 1 input, 32 outputs\n",
        "  \n",
        "weight={'w1':tf.Variable(tf.random_normal([5,5,1,32])),\n",
        "       'w2':tf.Variable(tf.random_normal([5,5,32,64])),\n",
        "       # fully connected, 7*7*64 inputs, 1024 outputs \n",
        "       'wc1':tf.Variable(tf.random_normal([7*7*64,1024])), \n",
        "       #1024 input and 10 output\n",
        "       'w_out':tf.Variable(tf.random_normal([1024,n_classes]))}\n",
        "  \n",
        "    \n",
        "biase={'b1':tf.Variable(tf.random_normal([32])),\n",
        "       'b2':tf.Variable(tf.random_normal([64])),\n",
        "       'bc1':tf.Variable(tf.random_normal([1024])),\n",
        "       'b_out':tf.Variable(tf.random_normal([n_classes]))}\n",
        "                             \n",
        "    \n",
        "    \n",
        "# Construct model\n",
        "pred=model(x,weight,biase,keep_prob)\n",
        "\n",
        "# Define loss and optimizer\n",
        "cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y,logits=pred))\n",
        "#Optimizer.\n",
        "\n",
        "optimizer=tf.train.AdamOptimizer().minimize(cost)\n",
        "\n",
        "\n",
        "# Evaluate model\n",
        "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "    \n",
        "    \n",
        "# Initializing the variables\n",
        "init=tf.global_variables_initializer()\n",
        "\n",
        "# Initialize the session.\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for epoch in range(training_epochs):\n",
        "        \n",
        "        avg_cost=0.0\n",
        "        avg_accuracy=0.0\n",
        "        n_batch=int(mnist.train.num_examples/batch_size)\n",
        "        for i in range(n_batch):\n",
        "            batch_x,batch_y=mnist.train.next_batch(batch_size)\n",
        "            _,batch_cost,batch_acc=sess.run([optimizer,cost,accuracy],feed_dict={x:batch_x,y:batch_y,keep_prob:dropout})\n",
        "            avg_cost+=batch_cost/n_batch\n",
        "            avg_accuracy+=batch_acc/n_batch\n",
        "            \n",
        "        print('The epoch',epoch)\n",
        "        print('The avg _cost is{} and the avg_accuracy is {}'.format(avg_cost,avg_accuracy))\n",
        "    \n",
        "          \n",
        "            \n",
        "          \n",
        "    print(\"Optimization Finished!\")\n",
        "    \n",
        "    print(\"Testing Accuracy:\", \\\n",
        "          sess.run(accuracy, feed_dict={x: mnist.test.images[:256],\n",
        "                                        y: mnist.test.labels[:256],\n",
        "                                        keep_prob: 1.}))\n",
        "                \n",
        "                \n",
        "            \n",
        "\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The epoch 0\n",
            "The avg _cost is5734.256632202426 and the avg_accuracy is 0.7872778263403257\n",
            "The epoch 1\n",
            "The avg _cost is832.3269768205843 and the avg_accuracy is 0.9218385780885782\n",
            "The epoch 2\n",
            "The avg _cost is438.4687374177239 and the avg_accuracy is 0.9420527389277397\n",
            "The epoch 3\n",
            "The avg _cost is258.3714501529862 and the avg_accuracy is 0.9566579254079268\n",
            "The epoch 4\n",
            "The avg _cost is186.21455447323657 and the avg_accuracy is 0.9629953379953393\n",
            "The epoch 5\n",
            "The avg _cost is133.10081047556054 and the avg_accuracy is 0.96989729020979\n",
            "The epoch 6\n",
            "The avg _cost is106.432566760668 and the avg_accuracy is 0.9723193473193475\n",
            "The epoch 7\n",
            "The avg _cost is77.3293100459315 and the avg_accuracy is 0.9769085081585078\n",
            "The epoch 8\n",
            "The avg _cost is62.659016896482065 and the avg_accuracy is 0.9796219405594399\n",
            "The epoch 9\n",
            "The avg _cost is51.587387914146326 and the avg_accuracy is 0.9819347319347327\n",
            "The epoch 10\n",
            "The avg _cost is40.46281712072613 and the avg_accuracy is 0.983974358974359\n",
            "The epoch 11\n",
            "The avg _cost is33.88735428945723 and the avg_accuracy is 0.9861232517482528\n",
            "The epoch 12\n",
            "The avg _cost is28.039997165647083 and the avg_accuracy is 0.986815268065269\n",
            "The epoch 13\n",
            "The avg _cost is25.48954755944875 and the avg_accuracy is 0.9877804487179491\n",
            "The epoch 14\n",
            "The avg _cost is21.0198769730175 and the avg_accuracy is 0.9896379662004673\n",
            "The epoch 15\n",
            "The avg _cost is19.251803630617783 and the avg_accuracy is 0.9904938811188829\n",
            "The epoch 16\n",
            "The avg _cost is17.287439986768167 and the avg_accuracy is 0.9910766317016343\n",
            "The epoch 17\n",
            "The avg _cost is15.939525111849774 and the avg_accuracy is 0.9916047494172524\n",
            "The epoch 18\n",
            "The avg _cost is13.987083506316711 and the avg_accuracy is 0.9921146561771585\n",
            "The epoch 19\n",
            "The avg _cost is13.648278536704858 and the avg_accuracy is 0.9923696095571124\n",
            "The epoch 20\n",
            "The avg _cost is10.461694165889174 and the avg_accuracy is 0.9938993298368332\n",
            "The epoch 21\n",
            "The avg _cost is11.290969995230604 and the avg_accuracy is 0.9935715326340356\n",
            "The epoch 22\n",
            "The avg _cost is9.703076523534094 and the avg_accuracy is 0.9939721736596766\n",
            "The epoch 23\n",
            "The avg _cost is10.35271300448133 and the avg_accuracy is 0.9940814393939424\n",
            "The epoch 24\n",
            "The avg _cost is8.308453066539368 and the avg_accuracy is 0.9951012529137565\n",
            "The epoch 25\n",
            "The avg _cost is6.9308557503342225 and the avg_accuracy is 0.9958661130536172\n",
            "The epoch 26\n",
            "The avg _cost is7.607304343173184 and the avg_accuracy is 0.9951012529137562\n",
            "The epoch 27\n",
            "The avg _cost is8.590315440126933 and the avg_accuracy is 0.995028409090913\n",
            "The epoch 28\n",
            "The avg _cost is6.338906356252919 and the avg_accuracy is 0.9961210664335702\n",
            "The epoch 29\n",
            "The avg _cost is7.196810233248248 and the avg_accuracy is 0.9960482226107266\n",
            "The epoch 30\n",
            "The avg _cost is5.8751146167469885 and the avg_accuracy is 0.9965399184149226\n",
            "The epoch 31\n",
            "The avg _cost is5.656606026978607 and the avg_accuracy is 0.9959571678321717\n",
            "The epoch 32\n",
            "The avg _cost is5.533664808836687 and the avg_accuracy is 0.9965399184149223\n",
            "The epoch 33\n",
            "The avg _cost is5.888389964562749 and the avg_accuracy is 0.9965945512820554\n",
            "The epoch 34\n",
            "The avg _cost is5.629824439117062 and the avg_accuracy is 0.9965034965035007\n",
            "The epoch 35\n",
            "The avg _cost is5.355780052040366 and the avg_accuracy is 0.9966673951048991\n",
            "The epoch 36\n",
            "The avg _cost is5.3655853597229575 and the avg_accuracy is 0.9971044580419621\n",
            "The epoch 37\n",
            "The avg _cost is3.7957846379354767 and the avg_accuracy is 0.9973958333333376\n",
            "The epoch 38\n",
            "The avg _cost is3.244898700491809 and the avg_accuracy is 0.9977600524475567\n",
            "The epoch 39\n",
            "The avg _cost is4.6617671601943185 and the avg_accuracy is 0.9969223484848523\n",
            "The epoch 40\n",
            "The avg _cost is4.186788444732227 and the avg_accuracy is 0.9974868881118926\n",
            "The epoch 41\n",
            "The avg _cost is4.393091810472085 and the avg_accuracy is 0.9971955128205169\n",
            "The epoch 42\n",
            "The avg _cost is3.607455381563494 and the avg_accuracy is 0.9976325757575801\n",
            "The epoch 43\n",
            "The avg _cost is3.6069938152993757 and the avg_accuracy is 0.9976872086247126\n",
            "The epoch 44\n",
            "The avg _cost is2.249963486918829 and the avg_accuracy is 0.9983428030303075\n",
            "The epoch 45\n",
            "The avg _cost is2.363467735115169 and the avg_accuracy is 0.998160693473198\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The epoch 46\n",
            "The avg _cost is3.6333808405650325 and the avg_accuracy is 0.9977600524475567\n",
            "The epoch 47\n",
            "The avg _cost is3.4322766759408228 and the avg_accuracy is 0.997577942890447\n",
            "The epoch 48\n",
            "The avg _cost is3.9974624934000564 and the avg_accuracy is 0.9974868881118925\n",
            "The epoch 49\n",
            "The avg _cost is2.8441827305633844 and the avg_accuracy is 0.9979785839160886\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99609375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8pEQreM33_wX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}